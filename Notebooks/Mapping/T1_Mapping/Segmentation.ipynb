{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876a6290-33ee-4f76-82e4-476aa36ea8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from   cnn4cmr.architectures import Unet, FCN\n",
    "import cnn4cmr.data_loaders.segmentation_dl as seg_dl\n",
    "import cnn4cmr.data_loaders.augmentations as augs\n",
    "import cnn4cmr.data_loaders.utils as utils\n",
    "from   cnn4cmr.architectures import custom_losses\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shapely\n",
    "from   shapely.geometry import Point, Polygon, mapping, shape\n",
    "from   imgaug import augmenters as iaa\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4e8e5a-f877-4c5b-a265-d73e18238c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "\n",
    "# get suid,sop list\n",
    "ds_path = '/Users/thomas/Documents/GitHub/cnn4cmr/Datasets/T1_dataset'\n",
    "suidlist = [p for p in os.listdir(os.path.join(ds_path, 'Imgs')) if '.DS' not in p]\n",
    "suid_sop_list = []\n",
    "for suid in suidlist:\n",
    "    for sop in [p.replace('.dcm','') for p in os.listdir(os.path.join(ds_path, 'Imgs', suid))]:\n",
    "        suid_sop_list.append((suid, sop))\n",
    "\n",
    "# define train, val, test\n",
    "n_imgs = len(suid_sop_list)\n",
    "n_train, n_val, n_test = int(n_imgs*0.6), int(n_imgs*0.8), n_imgs\n",
    "\n",
    "suid_sop_list_train = suid_sop_list[:n_val]\n",
    "suid_sop_list_val   = suid_sop_list[n_val:n_val]\n",
    "suid_sop_list_test  = suid_sop_list[n_val:]\n",
    "\n",
    "print('T1')\n",
    "print('Train images: ', len(suid_sop_list_train))\n",
    "print('Val images:   ', len(suid_sop_list_val))\n",
    "print('Test images:  ', len(suid_sop_list_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1df1b09-2b24-46cb-9c1f-6148217e5337",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### hyperparameters\n",
    "\n",
    "# limits, prior, increments, prob of prior, prob of mutation, operator, init value\n",
    "def init_t1_parameter_config():\n",
    "    t1_params = {'droprate':    0.15, \n",
    "                 # heatmap variances\n",
    "                 'heatmap_v1':  40, \n",
    "                 'heatmap_v2':  20, \n",
    "                 'heatmap_v3':  40, \n",
    "                 # affine 1\n",
    "                 'rotation':    270,\n",
    "                 # continue here\n",
    "                 'scale':       0.3,\n",
    "                 # affine 2\n",
    "                 'translate':   0.15, \n",
    "                 'shear':       8,\n",
    "                 # other augs\n",
    "                 'poolsize':    5,\n",
    "                 'noise':       0.5,\n",
    "                 'blur':        3.5,\n",
    "                 'mult_range':  0.4,\n",
    "                 'contrast':    0.3}\n",
    "    for w_i in range(1,3):\n",
    "        t1_params['w_'+str(w_i)] = 0.5\n",
    "    for w_i in range(3,8):\n",
    "        t1_params['w_'+str(w_i)] = 0.5\n",
    "    return t1_params\n",
    "\n",
    "hp_config = init_t1_parameter_config()\n",
    "for k,v in hp_config.items(): print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934fe3e0-e635-4400-9db3-cbead2f6de33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make unet config\n",
    "\n",
    "def init_unet_config(t1_parameter_config):\n",
    "    unet_config = {'net_depth': 6, 'in_ch': 1, 'st_ch': 16, 'out_ch': 1, \n",
    "                   'd_rate': t1_parameter_config['droprate'], # this parameter evolves\n",
    "                   'max_ch': 512, 'deep_supervision': True}\n",
    "    return unet_config\n",
    "\n",
    "# make Unet\n",
    "#config = init_unet_config(hp_config)\n",
    "#cont_cnn = Unet(config['net_depth'], config['in_ch'], config['st_ch'], config['out_ch'], \n",
    "#               d_rate=config['d_rate'], max_ch=config['max_ch'], deep_supervision=config['deep_supervision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b15c9cf-12b5-47b3-81e0-42024d295686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cnn_cont(device):\n",
    "    # make generator to get batch\n",
    "    # seed = epoch makes the images in random order but the same for each cnn in population\n",
    "    epoch      = 0\n",
    "    generator  = seg_dl.random_img_goldanno_generator(seg_dl.load_mapping_img_gold_anno, \n",
    "                                                      ds_path, \n",
    "                                                      suid_sop_list_train, \n",
    "                                                      256, \n",
    "                                                      bounding_box=True, \n",
    "                                                      path_to_boundingbox='/Users/thomas/Documents/GitHub/cnn4cmr/Datasets/T1_dataset/Predictions/Bbox_Epoch_115_trainedonall',\n",
    "                                                      seed=epoch)\n",
    "    \n",
    "    # hyperparameters\n",
    "    hp_config = init_t1_parameter_config()\n",
    "    \n",
    "    # make unet\n",
    "    config = init_unet_config(hp_config)\n",
    "    \n",
    "    cnn    = Unet(config['net_depth'], config['in_ch'], config['st_ch'], config['out_ch'], \n",
    "                  d_rate=config['d_rate'], max_ch=config['max_ch'], deep_supervision=config['deep_supervision'])\n",
    "    cnn.to(device)\n",
    "    # make Adam\n",
    "    optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n",
    "    \n",
    "    return cnn, optimizer, generator, hp_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8523509a-3cbc-48f2-8717-204711844c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step_cont(cnn, optimizer, generator, hp_config, device, epochs, suid_sop_list):\n",
    "    # make learning behaviour\n",
    "    batchsize, lr = 8, 0.001\n",
    "    criterion     = custom_losses.DeepSupervisionLoss(weights      = np.asarray([4/14, 2/14, 1/14, 4/14, 2/14, 1/14]), \n",
    "                                                      loss_modules = [custom_losses.DiceLoss(), custom_losses.BCELoss()])\n",
    "    # make augmentations\n",
    "    augmentations = augs.make_augmenter(hp_config)\n",
    "\n",
    "    batches_per_epoch = len(suid_sop_list) // batchsize\n",
    "    for epoch in range(1, epochs+1):\n",
    "        print(); print('\\tEpoch: ', epoch, ' of ', epochs, end='\\n\\t')\n",
    "        epoch_loss = 0\n",
    "        cnn.train()\n",
    "        # train loop\n",
    "        for i_batch in range(batches_per_epoch):\n",
    "            if i_batch%10==9: print('.', end='')\n",
    "            suid_sop_pairs, imgs, masks, masks2, masks3 = seg_dl.get_batch_mapping_imgs_masks(generator, augmentations, batchsize=batchsize, prepare_channels=True, deep_supervision=True)\n",
    "            imgs, masks, masks2, masks3 = torch.from_numpy(imgs).to(device), torch.from_numpy(masks).to(device), torch.from_numpy(masks2).to(device), torch.from_numpy(masks3).to(device)\n",
    "            \n",
    "            # train step\n",
    "            optimizer.zero_grad()\n",
    "            masks_pred, masks_pred2, masks_pred3 = cnn(imgs)\n",
    "            loss = criterion(masks_pred, masks_pred2, masks_pred3, masks, masks2, masks3)\n",
    "            loss.backward(); optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80934a44-9cf6-47c9-be0f-e6b961d00838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(path, epoch, prefix, model, optimizer, hp_config):\n",
    "    # make folders\n",
    "    path = os.path.join(path, 'epoch_'+str(epoch))\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "    dirs = [name for name in os.listdir(path) if os.path.isdir(os.path.join(path, name))]\n",
    "    \n",
    "    # hp config for storage\n",
    "    hp_config = {k:v for k,v in hp_config.items()}\n",
    "    # store everything\n",
    "    torch.save(model.state_dict(),     os.path.join(path, prefix+'model_state_dict.pth'))\n",
    "    torch.save(optimizer.state_dict(), os.path.join(path, prefix+'optim_state_dict.pth'))\n",
    "    torch.save(hp_config,              os.path.join(path, prefix+'hp_config.pth'))\n",
    "\n",
    "\n",
    "def load_checkpoint(folder_path, prefix):\n",
    "    model_state_dict       = torch.load(os.path.join(folder_path, prefix+'model_state_dict.pth'))\n",
    "    optimizer_state_dict   = torch.load(os.path.join(folder_path, prefix+'optim_state_dict.pth'))\n",
    "    hp_config_values       = torch.load(os.path.join(folder_path, prefix+'hp_config.pth'))\n",
    "    epoch = int(os.path.basename(folder_path).split('_')[-1])\n",
    "    # rebuild hp_config\n",
    "    hp_config = init_t1_parameter_config()\n",
    "    for k,v in hp_config_values.items(): hp_config[k] = hp_config_values[k]\n",
    "    return model_state_dict, optimizer_state_dict, hp_config, epoch\n",
    "\n",
    "def reload_checkpoint(folder_path, prefix):\n",
    "    # reload cnn and genetic states \n",
    "    model_state_dict, optimizer_state_dict, hp_config, epoch = load_checkpoint(folder_path, prefix)\n",
    "\n",
    "    # unet\n",
    "    config = init_unet_config(hp_config)\n",
    "    cnn    = Unet(config['net_depth'], config['in_ch'], config['st_ch'], config['out_ch'], d_rate=config['d_rate'], max_ch=config['max_ch'], deep_supervision=config['deep_supervision'])\n",
    "    cnn.load_state_dict(model_state_dict)\n",
    "    cnn.to(device)\n",
    "    \n",
    "    # adam optimizer\n",
    "    optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n",
    "    optimizer.load_state_dict(optimizer_state_dict)\n",
    "\n",
    "    # not necessary to create heatmaps, regardless of cont or kps\n",
    "    return epoch, cnn, optimizer, hp_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64718441-cd19-4624-ab69-ec018bd6347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device            = 'mps'\n",
    "cont_storage_path = '/Users/thomas/Documents/GitHub/cnn4cmr/trained_models/T1/Cont'\n",
    "n_epochs          = 15\n",
    "\n",
    "#cont_cnn, cont_optimizer, cont_generator, cont_hp_config = init_cnn_cont(device)\n",
    "\n",
    "train_step_cont(cont_cnn, cont_optimizer, cont_generator, cont_hp_config, \n",
    "                device, epochs=n_epochs, suid_sop_list=suid_sop_list_train+suid_sop_list_test)\n",
    "\n",
    "save_checkpoint(cont_storage_path, 115, 'cont_trainedonall_', cont_cnn, cont_optimizer, cont_hp_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1675a39b-e3e2-4a91-8988-b544e2f04fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4be208-9ffe-4aba-afae-af690c30b72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_ , cont_generator, _ = init_cnn_cont(device)\n",
    "\n",
    "cont_cnn, cont_optimizer, cont_hp_config = cnn, optimizer, hp_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eb12d2-1432-46d0-b087-e1011eb93cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "device            = 'mps'\n",
    "cont_storage_path = '/Users/thomas/Documents/GitHub/cnn4cmr/trained_models/T1/Cont'\n",
    "\n",
    "epoch, cnn, optimizer, hp_config = reload_checkpoint(os.path.join(cont_storage_path,'epoch_100'), 'cont_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89091814-6763-4535-b079-93cb23f5f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_annotation(type_name_2_mask, other_info):\n",
    "    ret = dict()\n",
    "    for (annotype, name, lcc), mask in type_name_2_mask.items():\n",
    "        if annotype=='keypoint':\n",
    "            assert  len(mask.shape)==2,    'Mask for ' + annotype + ' ' +  name + ' has more than two dimensions.'\n",
    "            point = utils.to_keypoint(heatmap_mask)\n",
    "            ret[name] = {'cont':               mapping(point),\n",
    "                         'contType':           other_info['contType'],\n",
    "                         'subpixelResolution': 1.0,\n",
    "                         'pixelSize':          other_info['pixelSize'],\n",
    "                         'imageSize':          other_info['imageSize']}\n",
    "        if annotype=='contour': #\n",
    "            assert  len(mask.shape)==2,    'Mask for ' + annotype + ' ' +  name + ' has more than two dimensions.'\n",
    "            assert  mask.dtype==np.uint8,  'Mask for ' + annotype + ' ' +  name + ' is not of type np.uint8.'\n",
    "            poly = utils.to_polygon(mask)\n",
    "            if lcc and poly.geom_type=='MultiPolygon': poly=max(poly.geoms, key=lambda p:p.area)\n",
    "            ret[name] = {'cont':               mapping(poly),\n",
    "                         'contType':           other_info['contType'],\n",
    "                         'subpixelResolution': 1.0,\n",
    "                         'pixelSize':          other_info['pixelSize'],\n",
    "                         'imageSize':          other_info['imageSize']}\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c55a462-2db3-4a76-9136-4237a11e65f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "import matplotlib.patches as patches\n",
    "import pydicom\n",
    "from pprint import pprint\n",
    "\n",
    "cnn = cnn.eval()\n",
    "noaugs = augs.make_noaugs_augmenter()\n",
    "#noaugs = augs.make_augmenter(hp_config)\n",
    "#test_generator  = seg_dl.random_img_goldanno_generator(ds_paths, suid_sop_list_test_lists, \n",
    "#                                                       256, bounding_box=True, \n",
    "#                                                       path_to_boundingbox='/Users/thomas/Documents/GitHub/cnn4cmr/Datasets/T2_dataset/Predictions/BBox_Epoch_50', \n",
    "#                                                       seed=epoch)\n",
    "test_generator  = seg_dl.random_img_goldanno_generator(seg_dl.load_mapping_img_gold_anno, \n",
    "                                                                   ds_path, \n",
    "                                                                   suid_sop_list_test, \n",
    "                                                                   256, bounding_box=True, \n",
    "                                                                   path_to_boundingbox='/Users/thomas/Documents/GitHub/cnn4cmr/Datasets/T1_dataset/Additional_Info',\n",
    "                                                                   seed=epoch)\n",
    "\n",
    "for i, ((suid,sop),(img,conts,kps)) in enumerate(test_generator):\n",
    "    try:\n",
    "        imgs = noaugs(images=[img])\n",
    "        pred = cnn(torch.from_numpy(np.asarray(imgs)).to(device).reshape(1,1,256,256))[0].cpu().detach().numpy().squeeze()\n",
    "    \n",
    "        print(pred.shape)\n",
    "        pixelspacing=pixelspacing = pydicom.dcmread(os.path.join(ds_path, 'Imgs', suid, sop+'.dcm'),stop_before_pixels=True).PixelSpacing\n",
    "        other_info = {'imageSize': img.shape,\n",
    "                      'pixelSize': pixelspacing,\n",
    "                      'contType':  'MYO'}\n",
    "        type_name_2_mask = {('contour', 'lv_myo', True): (pred>0.5).astype(np.uint8)}\n",
    "        anno = to_annotation(type_name_2_mask, other_info)\n",
    "        \n",
    "        fig,axes = plt.subplots(1,2, figsize=(14,7))\n",
    "        for ax in axes: ax.axis('off')\n",
    "        axes[0].imshow(img, cmap='gray', interpolation='nearest')\n",
    "        axes[1].imshow(imgs[0], cmap='gray', interpolation='nearest')\n",
    "        #axes[2].imshow(imgs[0]+2*(pred>0.5).astype(np.float32), cmap='gray', interpolation='nearest')\n",
    "    \n",
    "        x,y = shape(anno['lv_myo']['cont']).exterior.xy\n",
    "        axes[1].plot(x,y)\n",
    "        x,y = shape(anno['lv_myo']['cont']).interiors[0].xy\n",
    "        axes[1].plot(x,y)\n",
    "        \n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "        if i==200: break\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5095ad5f-1d9f-4068-8f02-00bf098fd770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn4cmr",
   "language": "python",
   "name": "cnn4cmr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
