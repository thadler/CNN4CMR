{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda099b4-3503-41ed-bc5d-f35614909f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from   cnn4cmr.architectures import Unet, FCN\n",
    "import cnn4cmr.data_loaders.segmentation_dl as seg_dl\n",
    "import cnn4cmr.data_loaders.augmentations as augs\n",
    "import cnn4cmr.data_loaders.utils as utils\n",
    "from   cnn4cmr.architectures import custom_losses\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from   shapely.geometry import Point, Polygon, mapping\n",
    "from   imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61fe8bc-85b5-4265-9532-f0ed63c72395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfef62d0-c4d4-4ba1-a79b-870170d94b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "\n",
    "# get suid,sop list\n",
    "ds_path = '/Users/thomas/Documents/GitHub/cnn4cmr/Datasets/T1_dataset'\n",
    "suidlist = [p for p in os.listdir(os.path.join(ds_path, 'Imgs')) if '.DS' not in p]\n",
    "suid_sop_list = []\n",
    "for suid in suidlist:\n",
    "    for sop in [p.replace('.dcm','') for p in os.listdir(os.path.join(ds_path, 'Imgs', suid))]:\n",
    "        suid_sop_list.append((suid, sop))\n",
    "\n",
    "# define train, val, test\n",
    "n_imgs = len(suid_sop_list)\n",
    "n_train, n_val, n_test = int(n_imgs*0.6), int(n_imgs*0.8), n_imgs\n",
    "\n",
    "suid_sop_list_train = suid_sop_list[:n_train]\n",
    "suid_sop_list_val   = suid_sop_list[n_train:n_val]\n",
    "suid_sop_list_test  = suid_sop_list[n_val:]\n",
    "\n",
    "print('Train images: ', len(suid_sop_list_train))\n",
    "print('Val images:   ', len(suid_sop_list_val))\n",
    "print('Test images:  ', len(suid_sop_list_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad97bab-8105-4fe0-aa02-fd9a9ce67a4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### hyperparameters\n",
    "\n",
    "# limits, prior, increments, prob of prior, prob of mutation, operator, init value\n",
    "def init_t1_parameter_config():\n",
    "    t1_params = {'droprate':    0.2, \n",
    "                 # heatmap variances\n",
    "                 'heatmap_v1':  19, \n",
    "                 'heatmap_v2':  9, \n",
    "                 'heatmap_v3':  15, \n",
    "                 # affine 1\n",
    "                 'rotation':    360,\n",
    "                 # continue here\n",
    "                 'scale':       0.25,\n",
    "                 # affine 2\n",
    "                 'translate':   0.1, \n",
    "                 'shear':       7,\n",
    "                 # other augs\n",
    "                 'poolsize':    5,\n",
    "                 'noise':       0.3,\n",
    "                 'blur':        2.5,\n",
    "                 'mult_range':  0.2,\n",
    "                 'contrast':    0.3}\n",
    "    for w_i in range(1,3):\n",
    "        t1_params['w_'+str(w_i)] = 0.5\n",
    "    for w_i in range(3,8):\n",
    "        t1_params['w_'+str(w_i)] = 0.2\n",
    "    return t1_params\n",
    "\n",
    "hp_config = init_t1_parameter_config()\n",
    "for k,v in hp_config.items(): print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962ad104-b842-43b0-a7f4-3840221dbbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make unet config\n",
    "\n",
    "def init_unet_config(t1_parameter_config):\n",
    "    unet_config = {'net_depth': 6, 'in_ch': 1, 'st_ch': 16, 'out_ch': 1, \n",
    "                   'd_rate': t1_parameter_config['droprate'], # this parameter evolves\n",
    "                   'max_ch': 512, 'deep_supervision': True}\n",
    "    return unet_config\n",
    "\n",
    "# make Unet\n",
    "#config = init_unet_config(hp_config)\n",
    "#cont_cnn = Unet(config['net_depth'], config['in_ch'], config['st_ch'], config['out_ch'], \n",
    "#               d_rate=config['d_rate'], max_ch=config['max_ch'], deep_supervision=config['deep_supervision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38379431-fa0b-4086-8e18-12953771a00f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666757a4-14fd-4113-a9cb-5121611a9a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cnn_bbox(device):\n",
    "    # make generator to get batch\n",
    "    # seed = epoch makes the images in random order but the same for each cnn in population\n",
    "    epoch      = 0\n",
    "    generator  = seg_dl.random_img_goldanno_generator(ds_path, suid_sop_list_train, 256, bounding_box=False, seed=epoch)\n",
    "    \n",
    "    # hyperparameters\n",
    "    hp_config = init_t1_parameter_config()\n",
    "    \n",
    "    # make unet\n",
    "    config = init_unet_config(hp_config)\n",
    "    \n",
    "    cnn    = Unet(config['net_depth'], config['in_ch'], config['st_ch'], config['out_ch'], d_rate=config['d_rate'], max_ch=config['max_ch'], deep_supervision=config['deep_supervision'])\n",
    "    cnn.to(device)\n",
    "    # make Adam\n",
    "    optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n",
    "    \n",
    "    return cnn, optimizer, generator, hp_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c0bb58-e40e-4d32-ace7-ec11508998c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step_bbox(cnn, optimizer, generator, hp_config, device, epochs, suid_sop_list):\n",
    "    # make learning behaviour\n",
    "    batchsize, lr = 8, 0.001\n",
    "    criterion     = custom_losses.DeepSupervisionLoss(weights      = np.asarray([4/14, 2/14, 1/14, 4/14, 2/14, 1/14]), \n",
    "                                                      loss_modules = [custom_losses.DiceLoss(), custom_losses.BCELoss()])\n",
    "    # make augmentations\n",
    "    augmentations = augs.make_augmenter(hp_config)\n",
    "\n",
    "    batches_per_epoch = len(suid_sop_list) // batchsize\n",
    "    for epoch in range(1, epochs+1):\n",
    "        print(); print('\\tEpoch: ', epoch, ' of ', epochs, end='\\n\\t')\n",
    "        epoch_loss = 0\n",
    "        cnn.train()\n",
    "        # train loop\n",
    "        for i_batch in range(batches_per_epoch):\n",
    "            if i_batch%10==9: print('.', end='')\n",
    "            suid_sop_pairs, imgs, masks, masks2, masks3 = seg_dl.get_batch_imgs_epimasks(generator, augmentations, batchsize=batchsize, prepare_channels=True, deep_supervision=True)\n",
    "            imgs, masks, masks2, masks3 = torch.from_numpy(imgs).to(device), torch.from_numpy(masks).to(device), torch.from_numpy(masks2).to(device), torch.from_numpy(masks3).to(device)\n",
    "            \n",
    "            # train step\n",
    "            optimizer.zero_grad()\n",
    "            masks_pred, masks_pred2, masks_pred3 = cnn(imgs)\n",
    "            loss = criterion(masks_pred, masks_pred2, masks_pred3, masks, masks2, masks3)\n",
    "            loss.backward(); optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f6ff61-9a75-4eff-bad5-70ef838a2870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(path, epoch, nr, prefix, model, optimizer, hp_config):\n",
    "    # make folders\n",
    "    path = os.path.join(path, 'epoch_'+str(epoch))\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "    dirs = [name for name in os.listdir(path) if os.path.isdir(os.path.join(path, name))]\n",
    "    folder_path = os.path.join(path, 'cnn_'+str(nr)) # get largest number add 1 and make new folder for contents\n",
    "    Path(folder_path).mkdir(parents=True, exist_ok=True)\n",
    "    # hp config for storage\n",
    "    hp_config = {k:v.value for k,v in hp_config.items()}\n",
    "    # store everything\n",
    "    torch.save(model.state_dict(),     os.path.join(folder_path, prefix+'model_state_dict.pth'))\n",
    "    torch.save(optimizer.state_dict(), os.path.join(folder_path, prefix+'optim_state_dict.pth'))\n",
    "    torch.save(hp_config,              os.path.join(folder_path, prefix+'hp_config.pth'))\n",
    "\n",
    "\n",
    "def load_checkpoint(folder_path, prefix):\n",
    "    model_state_dict       = torch.load(os.path.join(folder_path, prefix+'model_state_dict.pth'))\n",
    "    optimizer_state_dict   = torch.load(os.path.join(folder_path, prefix+'optim_state_dict.pth'))\n",
    "    hp_config_values       = torch.load(os.path.join(folder_path, prefix+'hp_config.pth'))\n",
    "    # rebuild hp_config\n",
    "    hp_config = init_t1_parameter_config()\n",
    "    for k,v in hp_config_values.items(): hp_config[k].value = hp_config_values[k]\n",
    "    return model_state_dict, optimizer_state_dict, hp_config, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47f6f71-6687-4c83-b13c-6259ee2064f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps'\n",
    "print('\\tInitializing cnns and training environment')\n",
    "#bbox_cnn, bbox_optimizer, bbox_generator, bbox_hp_config = init_cnn_bbox(device)\n",
    "\n",
    "#print('\\tTraining starts')\n",
    "train_step_bbox(bbox_cnn, bbox_optimizer, bbox_generator, bbox_hp_config, \n",
    "                device, epochs=3, suid_sop_list=suid_sop_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98180c5-c452-40e3-941a-93869e4b4100",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noaugs = augs.make_noaugs_augmenter()\n",
    "noaugs = augs.make_augmenter(hp_config)\n",
    "\n",
    "for i, ((suid,sop),(img,conts,kps)) in enumerate(bbox_generator):\n",
    "    imgs = noaugs(images=[img])\n",
    "    pred = bbox_cnn(torch.from_numpy(np.asarray(imgs)).to(device).reshape(1,1,256,256))[0].cpu().detach().numpy().squeeze()\n",
    "    fig,axes = plt.subplots(2,2, figsize=(10,10))\n",
    "    for ax_ in axes: \n",
    "        for ax in ax_: ax.axis('off')\n",
    "    axes[0,0].imshow(img, cmap='gray')\n",
    "    axes[0,1].imshow(imgs[0], cmap='gray')\n",
    "    axes[1,0].imshow(pred>0.5, cmap='gray')\n",
    "    axes[1,1].imshow(imgs[0]+2*(pred>0.5).astype(np.float32), cmap='gray')\n",
    "    plt.show()\n",
    "    if i==10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a86fec4-e778-4c63-8a13-00a7fb54dfbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn4cmr",
   "language": "python",
   "name": "cnn4cmr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
